1、线性分类算法vs非线性分类，NB为什么是线性分类器?
2、线性回归与逻辑回归是什么?
线性回归是拟合y，逻辑回归是拟合对数几率。选择应该是和数据集有关的。
另外，线性模型用于回归问题、二逻辑回归用于分类问题。逻辑回归的模型学习好之后
可以计算样本属于0后者1的概率从而是一个分类模型。

为什么由回归问题衍生的逻辑回归变成了分类模型呢？
对率回归面向的数据集是只要0-1标签的数据，那么从广义线性的角度考虑，就要选择一个
契合数据集的激活函数，自然就是sigmoid，于是自然构建对率回归的模型。所以从回归的
角度来看，逻辑回归是对“对率”的拟合。
又把它说成是分类问题，在于模型的输出在01之间，那么可以把y定义为分类为1的概率。
基于此，可以构建最大似然目标函数。这个时候模型学习好之后输出的仍然是一个实数
而不是0-1，但是模型客观上具有了分类的功能。
从这个角度看，分类是回归的结果，例如对学生划分为优良中差，就是对学生成绩(回归)的一个划分。
对率回归本质上是一个回归模型，但是具有分类的功能。


线性回归目标函数：最小二乘法(均方误差)
逻辑回归木变函数：最大似然函数(交叉熵)


3、基于规则的分类器有哪些？
决策树、随机深林。
4、聚类算法细节？
